{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dX-VF938tVc1",
        "outputId": "ac7dd0d8-720f-49c7-ff94-96de631b18d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: pycuda in /home/jians21/.local/lib/python3.10/site-packages (2022.2.2)\n",
            "Requirement already satisfied: appdirs>=1.4.0 in /home/jians21/.local/lib/python3.10/site-packages (from pycuda) (1.4.4)\n",
            "Requirement already satisfied: pytools>=2011.2 in /home/jians21/.local/lib/python3.10/site-packages (from pycuda) (2022.1.14)\n",
            "Requirement already satisfied: mako in /usr/lib/python3/dist-packages (from pycuda) (1.1.3)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /home/jians21/.local/lib/python3.10/site-packages (from pytools>=2011.2->pycuda) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0 in /home/jians21/.local/lib/python3.10/site-packages (from pytools>=2011.2->pycuda) (4.5.0)\n"
          ]
        }
      ],
      "source": [
        "# install the pycuda library\n",
        "!pip install pycuda \n",
        "!pip install numpy\n",
        "# if installed then ignore. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "zHilrYjFt6Sr",
        "outputId": "0cdfb56b-52fe-41a9-f265-c41ece6973c5"
      },
      "outputs": [],
      "source": [
        "# device initialization, memory cleanup and context creation\n",
        "import pycuda.autoinit\n",
        "# functions for memory handling, as allocation, deallocation and transfers, etc.\n",
        "import pycuda.driver as cuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bScjpcLZuSsy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-1.3572537e+01  5.3027329e+00 -2.3583326e+01 ... -5.2185833e+01\n",
            "   1.2429722e+01  1.6172363e+01]\n",
            " [ 5.9952621e+00  9.9136925e+00 -1.2643087e+01 ... -1.4589213e+01\n",
            "   4.9018795e+01  2.9290013e+00]\n",
            " [ 2.3234087e+01  1.5755710e+01  2.2314014e+01 ...  4.2463126e+00\n",
            "   1.2339674e+01 -6.3463940e+01]\n",
            " ...\n",
            " [-2.3722603e+01  7.4215782e+01  9.0173737e+01 ... -2.3927917e+00\n",
            "   3.7708251e+00  1.2135443e+01]\n",
            " [ 1.7693916e+01  5.6998487e+00  4.4510565e+00 ... -8.5599594e+01\n",
            "  -3.4983253e+01  8.2761641e+00]\n",
            " [-1.7904207e+01  2.8100306e+01  6.8855345e-02 ...  2.1453413e+01\n",
            "   3.5164215e+01  3.2302063e+01]]\n"
          ]
        }
      ],
      "source": [
        "'''tile version '''\n",
        "import pycuda.autoinit\n",
        "import pycuda.driver as cuda\n",
        "import numpy as np\n",
        "from pycuda.compiler import SourceModule\n",
        "\n",
        "# Define the size of the matrices and tile size\n",
        "M = 1024\n",
        "N = 1024\n",
        "K = 1024\n",
        "TILE_SIZE = 16\n",
        "\n",
        "# Generate two random matrices\n",
        "a = np.random.randn(M, K).astype(np.float32)\n",
        "b = np.random.randn(K, N).astype(np.float32)\n",
        "\n",
        "# Define the CUDA kernel function\n",
        "mod = SourceModule(\"\"\"\n",
        "  #define TILE_SIZE %(tile_size)d\n",
        "\n",
        "  __global__ void matmul(float *a, float *b, float *c, int m, int n, int k) {\n",
        "    __shared__ float s_a[TILE_SIZE][TILE_SIZE];\n",
        "    __shared__ float s_b[TILE_SIZE][TILE_SIZE];\n",
        "\n",
        "    int bx = blockIdx.x;\n",
        "    int by = blockIdx.y;\n",
        "    int tx = threadIdx.x;\n",
        "    int ty = threadIdx.y;\n",
        "\n",
        "    int row = by * TILE_SIZE + ty;\n",
        "    int col = bx * TILE_SIZE + tx;\n",
        "\n",
        "    float sum = 0.0;\n",
        "    for (int i = 0; i < (k-1)/TILE_SIZE+1; i++) {\n",
        "      if (row < m && i*TILE_SIZE+tx < k) {\n",
        "        s_a[ty][tx] = a[row*k + i*TILE_SIZE+tx];\n",
        "      } else {\n",
        "        s_a[ty][tx] = 0.0;\n",
        "      }\n",
        "      if (i*TILE_SIZE+ty < k && col < n) {\n",
        "        s_b[ty][tx] = b[(i*TILE_SIZE+ty)*n + col];\n",
        "      } else {\n",
        "        s_b[ty][tx] = 0.0;\n",
        "      }\n",
        "      __syncthreads();\n",
        "\n",
        "      for (int j = 0; j < TILE_SIZE; j++) {\n",
        "        sum += s_a[ty][j] * s_b[j][tx];\n",
        "      }\n",
        "      __syncthreads();\n",
        "    }\n",
        "    if (row < m && col < n) {\n",
        "      c[row*n+col] = sum;\n",
        "    }\n",
        "  }\n",
        "\"\"\" % {\"tile_size\": TILE_SIZE})\n",
        "\n",
        "# Get the kernel function from the module\n",
        "matmul = mod.get_function(\"matmul\")\n",
        "\n",
        "# Allocate memory on the GPU\n",
        "a_gpu = cuda.mem_alloc(a.nbytes)\n",
        "b_gpu = cuda.mem_alloc(b.nbytes)\n",
        "c_gpu = cuda.mem_alloc(M*N * np.dtype(np.float32).itemsize)\n",
        "\n",
        "# Copy the matrices to the GPU\n",
        "cuda.memcpy_htod(a_gpu, a)\n",
        "cuda.memcpy_htod(b_gpu, b)\n",
        "\n",
        "# Launch the kernel function\n",
        "grid = ((N-1)//TILE_SIZE+1, (M-1)//TILE_SIZE+1, 1)\n",
        "block = (TILE_SIZE, TILE_SIZE, 1)\n",
        "matmul(a_gpu, b_gpu, c_gpu, np.int32(M), np.int32(N), np.int32(K), block=block, grid=grid)\n",
        "\n",
        "# Copy the result from the GPU to the CPU\n",
        "c = np.empty((M, N), dtype=np.float32)\n",
        "cuda.memcpy_dtoh(c, c_gpu)\n",
        "\n",
        "# Print the result\n",
        "print(c)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# move the output content to the output file, which is \"product.dat\"\n",
        "sys.stdout = open(sys.argv[1], \"w\")\n",
        "\n",
        "# print the output array, which is the array c\n",
        "for i in range(width):\n",
        "    for j in range(width):\n",
        "        print(\"%f\\t\" % c[i*width+j], end=\"\")\n",
        "    print()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
